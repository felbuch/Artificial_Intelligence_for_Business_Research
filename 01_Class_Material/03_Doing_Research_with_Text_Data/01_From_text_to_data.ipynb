{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484fac4e-0e3b-4bb4-8c61-b28792ccfa65",
   "metadata": {},
   "source": [
    "# Classical NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fefd73-f2fd-411e-813b-a677791760bf",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "76dd2747-e308-4fef-a127-03780b92bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc87cf3-0f39-4909-82ce-c4b011f2e433",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "461293fa-ee45-43e6-aba8-dc1bd1b6380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "711ebe45-6052-47c9-b613-98c5f4fec08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(url, encoding='latin1', usecols=['v1','v2'])\n",
    "data.columns = ['label','raw_text']\n",
    "data['text'] = data.raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2cfb0861-4ecd-4649-aeb1-d1e1302e360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>ham</td>\n",
       "      <td>Babe! How goes that day ? What are you up to ?...</td>\n",
       "      <td>Babe! How goes that day ? What are you up to ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ham</td>\n",
       "      <td>I know that my friend already told that.</td>\n",
       "      <td>I know that my friend already told that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes:)here tv is always available in work place..</td>\n",
       "      <td>Yes:)here tv is always available in work place..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>ham</td>\n",
       "      <td>Really? I crashed out cuddled on my sofa.</td>\n",
       "      <td>Really? I crashed out cuddled on my sofa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have WON a guaranteed å£1000 cash or a å£2...</td>\n",
       "      <td>You have WON a guaranteed å£1000 cash or a å£2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am going to sao mu today. Will be done only ...</td>\n",
       "      <td>I am going to sao mu today. Will be done only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>ham</td>\n",
       "      <td>She.s fine. I have had difficulties with her p...</td>\n",
       "      <td>She.s fine. I have had difficulties with her p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>spam</td>\n",
       "      <td>YES! The only place in town to meet exciting a...</td>\n",
       "      <td>YES! The only place in town to meet exciting a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k:)after that placement there ah?</td>\n",
       "      <td>Oh k:)after that placement there ah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ham</td>\n",
       "      <td>Watching tv lor...</td>\n",
       "      <td>Watching tv lor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           raw_text  \\\n",
       "4119   ham  Babe! How goes that day ? What are you up to ?...   \n",
       "557    ham           I know that my friend already told that.   \n",
       "233    ham   Yes:)here tv is always available in work place..   \n",
       "2736   ham          Really? I crashed out cuddled on my sofa.   \n",
       "1873  spam  You have WON a guaranteed å£1000 cash or a å£2...   \n",
       "123    ham  I am going to sao mu today. Will be done only ...   \n",
       "5198   ham  She.s fine. I have had difficulties with her p...   \n",
       "3756  spam  YES! The only place in town to meet exciting a...   \n",
       "4734   ham               Oh k:)after that placement there ah?   \n",
       "482    ham                                 Watching tv lor...   \n",
       "\n",
       "                                                   text  \n",
       "4119  Babe! How goes that day ? What are you up to ?...  \n",
       "557            I know that my friend already told that.  \n",
       "233    Yes:)here tv is always available in work place..  \n",
       "2736          Really? I crashed out cuddled on my sofa.  \n",
       "1873  You have WON a guaranteed å£1000 cash or a å£2...  \n",
       "123   I am going to sao mu today. Will be done only ...  \n",
       "5198  She.s fine. I have had difficulties with her p...  \n",
       "3756  YES! The only place in town to meet exciting a...  \n",
       "4734               Oh k:)after that placement there ah?  \n",
       "482                                  Watching tv lor...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339bfdf3-ad5d-408a-ab7b-b8c97cbccfdd",
   "metadata": {},
   "source": [
    "## Pre-processing steps\n",
    "\n",
    "1. Remove punctuation\n",
    "2. Remove capitalization\n",
    "3. Remove stopwords\n",
    "4. Tokenization\n",
    "5. Stemming / Lemmatizing\n",
    "6. Expressing text as numbers. (Computer can only work with numbers, you know...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1b9c1-442e-433c-bd2f-2c473e9afa4f",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20d282fc-bd31-41b0-a03a-76dd9c62eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a10b3cc-1395-47d3-9813-16c3aec0aef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  Go until jurong point crazy Available only in ...  \n",
       "1                            Ok lar Joking wif u oni  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3        U dun say so early hor U c already then say  \n",
       "4  Nah I dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data.text.apply(remove_punctuation)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad9df80-001e-42df-9088-6a4e76ea2c9a",
   "metadata": {},
   "source": [
    "## Remove capitalization\n",
    "Let's set everything to lower case.\n",
    "(Quersion: Why not upper case?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "15210de6-6625-476f-a66e-6ca5917c99d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']= data['text'].apply(lambda x: x.lower())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d957f2-d61f-48d1-9eee-0f93792d9d7c",
   "metadata": {},
   "source": [
    "## Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1dd0e06a-acf8-49b5-9d22-ed047cc8c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_number(string):\n",
    "    return(re.sub(r'[0-9]*','',string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "60e2bf32-9ebf-4560-87e1-4201b425f55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in  a wkly comp to win fa cup final...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data.text.apply(lambda x: remove_number(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb368f46-84f1-4a62-9a8e-e05248c93001",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "* What is a token?\n",
    "* Does token = word?\n",
    "* grams, bigrams, trigrams and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7c3ab324-3f9f-4328-82c6-4393b2c4d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = re.split(' ',text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4056a028-9948-4aa7-9383-5fba0f66843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.text.apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "100d7173-5208-4334-8fb1-f1d2d34814c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, , a, wkly, comp, to, win, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, , a, wkly, comp, to, win, fa...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae23d34-9cca-465d-8c55-f4018b4920cd",
   "metadata": {},
   "source": [
    "## Remove stopwords\n",
    "What is a stopword?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8ea01173-f2bd-4874-a9fb-466eee91a1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c831ff7f-306a-4e92-9c8d-0cf1e28202d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4474c95b-2bcf-4ef1-9887-3410ccd50aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, , wkly, comp, win, fa, cup, fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, , wkly, comp, win, fa, cup, fina...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data.text.apply(remove_stopwords)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15124045-d19c-4528-822e-23a6cc41c829",
   "metadata": {},
   "source": [
    "## Stemming / Lemmatizing\n",
    "* What's the difference?\n",
    "* Which one do you think is better?\n",
    "\n",
    "Let's use lemmatizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a83a8c03-2571-4834-85f1-25a20a87ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "059aae7e-6b6d-4180-86bd-9613af7883f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs -> dog\n",
      "children -> child\n",
      "abaci -> abacus\n"
     ]
    }
   ],
   "source": [
    "for example in ['dogs','children','abaci']:\n",
    "    print(example, '->' ,wordnet_lemmatizer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b98fc25f-dff2-40ca-bc10-8f2e2cf072d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, , wkly, comp, win, fa, cup, fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, , wkly, comp, win, fa, cup, fina...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x:lemmatizer(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450562ea-bdb0-4f8b-a351-8c945896017d",
   "metadata": {},
   "source": [
    "Note: In the last row, _goes_ has changed to _go_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4cbd7-e8d2-4fcc-86fb-ce38a5d5472e",
   "metadata": {},
   "source": [
    "## Expressing text as numbers\n",
    "\n",
    "* Document-Term Matrix (DTM)\n",
    "* Embeddings\n",
    "\n",
    "Let's save embeddings for later. For now, let's dive into the DTM\n",
    "\n",
    "There are two kinds of DTM:\n",
    "\n",
    "* those based on _term frequency_, a.k.a. _Bag of Words_ (BOW)\n",
    "* those based on _TF-IDF_\n",
    "\n",
    "_Scikit-Learn_ has functions to build both kinds of DTMs, but it requires text (not a list of tokens). So let's join our tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bdedc3fb-56e2-4d16-a598-4a0606d4c56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry  wkly comp win fa cup final tkts st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           raw_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                text  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry  wkly comp win fa cup final tkts st...  \n",
       "3                u dun say early hor u c already say  \n",
       "4           nah dont think go usf life around though  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data.text.apply(lambda x: ' '.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f889a-134d-4d1a-add3-4ccb787aa376",
   "metadata": {},
   "source": [
    "### DTMs based on term frequency (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9ada4fc-937b-457c-98a8-650a20484c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "dtm = vectorizer.fit_transform(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "56652614-777d-419c-9c1d-554f37ab15c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7918)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "762695b3-2f23-4ae6-9682-3da26337d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(dtm.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c4605-d7fa-4b1e-8461-653784b52837",
   "metadata": {},
   "source": [
    "The DTM s __sparse__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8d33d4da-0032-4125-a5c3-be445d414e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(DTM):\n",
    "    \n",
    "    td = pd.DataFrame(DTM.todense()).iloc[:5]  \n",
    "    td.columns = vectorizer.get_feature_names_out()\n",
    "    term_document_matrix = td.T\n",
    "    term_document_matrix.columns = ['Doc '+str(i) for i in range(1, 6)]\n",
    "    term_document_matrix['total_count'] = term_document_matrix.sum(axis=1)\n",
    "    \n",
    "    # Top 25 words \n",
    "    term_document_matrix = term_document_matrix.sort_values(by ='total_count',ascending=False)[:20] \n",
    "    \n",
    "    # Print the first 10 rows \n",
    "    print(term_document_matrix.drop(columns=['total_count']).head(20))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca66949f-4c13-4c43-a343-0a12debe9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Doc 1  Doc 2  Doc 3  Doc 4  Doc 5\n",
      "go               1      0      0      0      1\n",
      "fa               0      0      2      0      0\n",
      "say              0      0      0      2      0\n",
      "entry            0      0      2      0      0\n",
      "questionstd      0      0      1      0      0\n",
      "think            0      0      0      0      1\n",
      "wif              0      1      0      0      0\n",
      "ok               0      1      0      0      0\n",
      "apply            0      0      1      0      0\n",
      "jurong           1      0      0      0      0\n",
      "over             0      0      1      0      0\n",
      "around           0      0      0      0      1\n",
      "point            1      0      0      0      0\n",
      "comp             0      0      1      0      0\n",
      "dun              0      0      0      1      0\n",
      "wkly             0      0      1      0      0\n",
      "may              0      0      1      0      0\n",
      "txt              0      0      1      0      0\n",
      "life             0      0      0      0      1\n",
      "lar              0      1      0      0      0\n"
     ]
    }
   ],
   "source": [
    "visualize(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403212fc-481b-4c80-a597-3e8a4c97be1b",
   "metadata": {},
   "source": [
    "_Comments:_\n",
    "* What does each row/column of the DTM represent?\n",
    "* Why are there so many zeros?\n",
    "    * Sparse matrix\n",
    "    * Implications for storage in memory and computation\n",
    "* Notice any problems with this DTM? Can we do any better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d8303-6d6a-4947-9962-6822d8ee5171",
   "metadata": {},
   "source": [
    "### DTMs base on TF-IDFs\n",
    "\n",
    "$$\n",
    "TF-IDF = \\frac{\\text{Frequency of term } i \\text{ in a document}}{\\text{Number of words in that document}} \\times \\log_2\\left(\\frac{\\text{Number of documents in corpus}}{\\text{Number of documents that contain term } i}\\right)\n",
    "$$\n",
    "\n",
    "* A measure of how much a term $i$ is important for a document $D$\n",
    "* Building blocks:\n",
    "    * Term Frequency\n",
    "    * Document Frequency\n",
    "    * Inverse Document Frequency\n",
    "* What is the rationale behind TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c14c76d4-901c-4a9c-84f7-efb880087fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_DTM = tfidf_vectorizer.fit_transform(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "229d3cf8-7ce7-48a0-9f42-f7747bb0573c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7918)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_DTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "689879e9-6ed7-4d9d-8547-1bd67051e4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_DTM.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "05b579d2-04d8-4f89-a03a-609670dff81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Doc 1     Doc 2     Doc 3     Doc 4     Doc 5\n",
      "say      0.000000  0.000000  0.000000  0.601553  0.000000\n",
      "oni      0.000000  0.546256  0.000000  0.000000  0.000000\n",
      "hor      0.000000  0.000000  0.000000  0.523599  0.000000\n",
      "joking   0.000000  0.523327  0.000000  0.000000  0.000000\n",
      "fa       0.000000  0.000000  0.499030  0.000000  0.000000\n",
      "nah      0.000000  0.000000  0.000000  0.000000  0.450358\n",
      "usf      0.000000  0.000000  0.000000  0.000000  0.444936\n",
      "wif      0.000000  0.431339  0.000000  0.000000  0.000000\n",
      "lar      0.000000  0.408051  0.000000  0.000000  0.000000\n",
      "go       0.155085  0.000000  0.000000  0.000000  0.246698\n",
      "though   0.000000  0.000000  0.000000  0.000000  0.394408\n",
      "entry    0.000000  0.000000  0.382427  0.000000  0.000000\n",
      "early    0.000000  0.000000  0.000000  0.378247  0.000000\n",
      "jurong   0.349890  0.000000  0.000000  0.000000  0.000000\n",
      "amore    0.349890  0.000000  0.000000  0.000000  0.000000\n",
      "dun      0.000000  0.000000  0.000000  0.348435  0.000000\n",
      "around   0.000000  0.000000  0.000000  0.000000  0.346766\n",
      "life     0.000000  0.000000  0.000000  0.000000  0.335945\n",
      "buffet   0.334008  0.000000  0.000000  0.000000  0.000000\n",
      "already  0.000000  0.000000  0.000000  0.315437  0.000000\n"
     ]
    }
   ],
   "source": [
    "visualize(tfidf_DTM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de63e53f-3d65-40ce-8bbd-52e6984123f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## All-in-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bf47045d-410a-457a-8471-ae0225df09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "\n",
    "    data['text'] = data.raw_text\n",
    "    data['text'] = data.text.apply(remove_punctuation)\n",
    "    data['text']= data['text'].apply(lambda x: x.lower())\n",
    "    data['text'] = data.text.apply(lambda x: remove_number(x))\n",
    "    data['text'] = data.text.apply(tokenization)\n",
    "    data['text'] = data.text.apply(remove_stopwords)\n",
    "    data['text'] = data['text'].apply(lambda x:lemmatizer(x))\n",
    "    data['text'] = data['text'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "49eb4056-76f7-4139-945f-ebefdd315f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry  wkly comp win fa cup final tkts st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried  contact u u å£ pound prize  cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>ì b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity  mood soany suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like id interested buying s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           raw_text  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                                   text  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry  wkly comp win fa cup final tkts st...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4              nah dont think go usf life around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tried  contact u u å£ pound prize  cla...  \n",
       "5568                        ì b going esplanade fr home  \n",
       "5569                        pity  mood soany suggestion  \n",
       "5570  guy bitching acted like id interested buying s...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1328d2-befa-4259-821a-01731a58b5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
